{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# As is this script scores 0.71+ on the leaderboard. If you download and run\n",
    "# at home, you can tweak the parameters as described in the Discussion\n",
    "# to get 0.90+\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy import fft\n",
    "from numpy.random import randint\n",
    "# Lasagne (& friends) imports\n",
    "import theano\n",
    "from nolearn.lasagne import BatchIterator, NeuralNet\n",
    "from lasagne.objectives import aggregate, binary_crossentropy\n",
    "from lasagne.layers import InputLayer, DropoutLayer, DenseLayer,Conv1DLayer,MaxPool1DLayer\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from theano.tensor.nnet import sigmoid\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Silence some warnings from lasagne\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*topo.*')\n",
    "warnings.filterwarnings('ignore', module='.*lasagne.init.*')\n",
    "warnings.filterwarnings('ignore', module='.*nolearn.lasagne.*')\n",
    "\n",
    "SUBJECTS = list(range(1,13))\n",
    "TRAIN_SERIES = list(range(1,9))\n",
    "TEST_SERIES = [9,10]\n",
    "\n",
    "N_ELECTRODES = 32\n",
    "N_EVENTS = 6\n",
    "\n",
    "# We train on TRAIN_SIZE randomly selected location each \"epoch\" (yes, that's\n",
    "# not really an epoch). One-fifth of these locations are used for validation,\n",
    "# hence the 5*X format, to make it clear what the number of validation points\n",
    "# is.\n",
    "TRAIN_SIZE = 5*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We encapsulate the event / electrode data in a Source object. \n",
    "\n",
    "class Source:\n",
    "\n",
    "    mean = None\n",
    "    std = None\n",
    "\n",
    "    def load_raw_data(self, subject, series):\n",
    "        raw_data = [self.read_csv(self.path(subject, i, \"data\")) for i in series]\n",
    "        self.data = np.concatenate(raw_data, axis=0)\n",
    "        raw_events = [self.read_csv(self.path(subject, i, \"events\")) for i in series]\n",
    "        self.events = np.concatenate(raw_events, axis=0)\n",
    "    \n",
    "    def normalize(self):\n",
    "        self.data -= self.mean\n",
    "        self.data /= self.std\n",
    "        \n",
    "    @staticmethod\n",
    "    def path(subject, series, kind):\n",
    "        prefix = \"train\" if (series in TRAIN_SERIES) else \"test\"\n",
    "        #return \"../input/{0}/subj{1}_series{2}_{3}.csv\".format(prefix, subject, series, kind)\n",
    "        return \"{0}/subj{1}_series{2}_{3}.csv\".format(prefix, subject, series, kind)\n",
    "    \n",
    "    csv_cache = {}\n",
    "    @classmethod\n",
    "    def read_csv(klass, path):\n",
    "        if path not in klass.csv_cache:\n",
    "            if len(klass.csv_cache): # Only cache last value\n",
    "                klass.csv_cache.popitem() # Need this or we run out of memory in Kaggle scripts\n",
    "            klass.csv_cache[path] = pandas.read_csv(path, index_col=0).values\n",
    "        return klass.csv_cache[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainSource(Source):\n",
    "\n",
    "    def __init__(self, subject, series_list):\n",
    "        self.load_raw_data(subject, series_list)\n",
    "        self.mean = self.data.mean(axis=0)\n",
    "        self.std = self.data.std(axis=0)\n",
    "        self.normalize()\n",
    "        self.principle_components = scipy.linalg.svd(self.data, full_matrices=False)\n",
    "        self.std2 = self.data.std(axis=0)\n",
    "        self.data /= self.std2\n",
    "\n",
    "        \n",
    "# Note that Test/Submit sources use the mean/std from the training data.\n",
    "# This is both standard practice and avoids using future data in theano\n",
    "# test set.\n",
    "\n",
    "class TestSource(Source):\n",
    "\n",
    "    def __init__(self, subject, series, train_source):\n",
    "        self.load_raw_data(subject, series)\n",
    "        self.mean = train_source.mean\n",
    "        self.std = train_source.std\n",
    "        self.principle_components = train_source.principle_components\n",
    "        self.normalize()\n",
    "        self.data /= train_source.std2\n",
    "        \n",
    "\n",
    "class SubmitSource(TestSource):\n",
    "\n",
    "    def __init__(self, subject, a_series, train_source):\n",
    "        TestSource.__init__(self, subject, [a_series], train_source)\n",
    "\n",
    "    def load_raw_data(self, subject, series):\n",
    "        [a_series] = series\n",
    "        self.data = self.read_csv(self.path(subject, a_series, \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lay out the Neural net.\n",
    "class LayerFactory:\n",
    "    \"\"\"Helper class that makes laying out Lasagne layers more pleasant\"\"\"\n",
    "    def __init__(self):\n",
    "        self.layer_cnt = 0\n",
    "        self.kwargs = {}\n",
    "    def __call__(self, layer, layer_name=None, **kwargs):\n",
    "        self.layer_cnt += 1\n",
    "        name = layer_name or \"layer{0}\".format(self.layer_cnt)\n",
    "        for k, v in kwargs.items():\n",
    "            self.kwargs[\"{0}_{1}\".format(name, k)] = v\n",
    "        return (name, layer) \n",
    "\n",
    "\n",
    "SAMPLE_SIZE = 2048 #ES:512 # Larger (2048 perhaps) would be better\n",
    "# We are downsample without low-pass filtering here. You should probably filter\n",
    "# to avoid aliasing of the data.\n",
    "DOWNSAMPLE = 8 \n",
    "TIME_POINTS = SAMPLE_SIZE // DOWNSAMPLE\n",
    "    \n",
    "class IndexBatchIterator(BatchIterator):\n",
    "    \"\"\"Generate BatchData from indices.\n",
    "    \n",
    "    Rather than passing the data into the fit function, instead we just pass in indices to\n",
    "    the data.  The actual data is then grabbed from a Source object that is passed in at\n",
    "    the creation of the IndexBatchIterator. Passing in a '-1' grabs a random value from\n",
    "    the Source.\n",
    "    \n",
    "    As a result, an \"epoch\" here isn't a traditional epoch, which looks at all the\n",
    "    time points. Instead a random subsamle of 0.8*TRAIN_SIZE points from the\n",
    "    training data are used each \"epoch\" and 0.2 TRAIN_SIZE points are uses for\n",
    "    validation.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, source, *args, **kwargs):\n",
    "        super(IndexBatchIterator, self).__init__(*args, **kwargs)\n",
    "        self.source = source\n",
    "        if source is not None:\n",
    "            # Tack on (SAMPLE_SIZE-1) copies of the first value so that it is easy to grab\n",
    "            # SAMPLE_SIZE POINTS even from the first location.\n",
    "            x = source.data\n",
    "            self.augmented = np.zeros([len(x)+(SAMPLE_SIZE-1), N_ELECTRODES], dtype=np.float32)\n",
    "            self.augmented[SAMPLE_SIZE-1:] = x\n",
    "            self.augmented[:SAMPLE_SIZE-1] = x[0]\n",
    "        self.Xbuf = np.zeros([self.batch_size, N_ELECTRODES, TIME_POINTS], np.float32) \n",
    "        self.Ybuf = np.zeros([self.batch_size, N_EVENTS], np.float32) \n",
    "    \n",
    "    def transform(self, X_indices, y_indices):\n",
    "        X_indices, y_indices = super(IndexBatchIterator, self).transform(X_indices, y_indices)\n",
    "        [count] = X_indices.shape\n",
    "        # Use preallocated space\n",
    "        X = self.Xbuf[:count]\n",
    "        Y = self.Ybuf[:count]\n",
    "        for i, ndx in enumerate(X_indices):\n",
    "            if ndx == -1:\n",
    "                ndx = np.random.randint(len(self.source.events))\n",
    "            sample = self.augmented[ndx:ndx+SAMPLE_SIZE]\n",
    "            # Reverse so we get most recent point, otherwise downsampling drops the last\n",
    "            # DOWNSAMPLE-1 points.\n",
    "            X[i] = sample[::-1][::DOWNSAMPLE].transpose()\n",
    "            if y_indices is not None:\n",
    "                Y[i] = self.source.events[ndx]\n",
    "        Y = None if (y_indices is None) else Y\n",
    "        return X, Y\n",
    "    \n",
    "\n",
    "# Simple / Naive net. Borrows from Daniel Nouri's Facial Keypoint Detection Tutorial \n",
    "    \n",
    "def create_net(train_source, test_source, batch_size=128, max_epochs=20): \n",
    "    \n",
    "    batch_iter_train = IndexBatchIterator(train_source, batch_size=batch_size)\n",
    "    batch_iter_test  = IndexBatchIterator(test_source, batch_size=batch_size)\n",
    "    LF = LayerFactory()\n",
    "\n",
    "    dense = 1024 #196 # larger (1024 perhaps) would be better\n",
    "    \n",
    "    layers = [\n",
    "        LF(InputLayer, shape=(None, N_ELECTRODES, TIME_POINTS)), \n",
    "        LF(DropoutLayer, p=0.5),\n",
    "        # This first layer condenses N_ELECTRODES down to num_filters.\n",
    "        # Since the electrode results are reportedly highly reduntant this\n",
    "        # should speed things up without sacrificing accuracy. It may\n",
    "        # also increase stability. This was 8 in an earlier version.\n",
    "        LF(Conv1DLayer, num_filters=4, filter_size=1, nonlinearity=None),\n",
    "        # Try one convolutional layer\n",
    "        LF(Conv1DLayer, num_filters=8, filter_size=5, pad=\"same\"),\n",
    "        # Maxpooling is more typically done with a pool_size of 2\n",
    "        LF(MaxPool1DLayer, pool_size=4),\n",
    "        # Standard fully connected net from here on out.\n",
    "        LF(DropoutLayer, p=0.5),\n",
    "        LF(DenseLayer, num_units=dense),\n",
    "        LF(DropoutLayer, p=0.5),\n",
    "        LF(DenseLayer, num_units=dense),\n",
    "        LF(DropoutLayer, p=0.5),\n",
    "        LF(DenseLayer, layer_name=\"output\", num_units=N_EVENTS, nonlinearity=sigmoid)\n",
    "    ]\n",
    "    \n",
    "    def loss(x,t):\n",
    "        return aggregate(binary_crossentropy(x, t))\n",
    "    \n",
    "    nnet =  NeuralNet(\n",
    "        y_tensor_type = theano.tensor.matrix,\n",
    "        layers = layers,\n",
    "        batch_iterator_train = batch_iter_train,\n",
    "        batch_iterator_test = batch_iter_test,\n",
    "        max_epochs=max_epochs,\n",
    "        verbose=1,\n",
    "        update = nesterov_momentum, \n",
    "        update_learning_rate = 0.02,\n",
    "        update_momentum = 0.9,\n",
    "        objective_loss_function = loss,\n",
    "        regression = True,\n",
    "        **LF.kwargs\n",
    "        )\n",
    "\n",
    "    return nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Subject:', 1)\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.21326\u001b[0m       \u001b[32m0.26775\u001b[0m      0.79649  3.03s\n",
      "      2       \u001b[36m0.15196\u001b[0m       \u001b[32m0.22148\u001b[0m      0.68612  2.98s\n",
      "      3       \u001b[36m0.14080\u001b[0m       0.25584      0.55035  2.95s\n",
      "      4       0.14921       0.24865      0.60008  2.93s\n",
      "      5       \u001b[36m0.14047\u001b[0m       0.26315      0.53378  2.95s\n",
      "      6       \u001b[36m0.14041\u001b[0m       0.24624      0.57023  2.93s\n",
      "      7       \u001b[36m0.13151\u001b[0m       \u001b[32m0.21953\u001b[0m      0.59905  2.94s\n",
      "      8       0.14326       0.22928      0.62481  2.92s\n",
      "      9       0.14553       0.25515      0.57036  2.97s\n",
      "     10       0.13721       \u001b[32m0.21497\u001b[0m      0.63826  2.94s\n",
      "     11       0.13450       \u001b[32m0.20724\u001b[0m      0.64899  2.97s\n",
      "     12       0.13668       0.21213      0.64434  2.94s\n",
      "     13       \u001b[36m0.12894\u001b[0m       0.21518      0.59921  2.95s\n",
      "     14       \u001b[36m0.12315\u001b[0m       0.23165      0.53159  2.92s\n",
      "     15       0.12624       \u001b[32m0.19945\u001b[0m      0.63292  2.94s\n",
      "     16       \u001b[36m0.11861\u001b[0m       0.20317      0.58378  2.96s\n",
      "     17       0.12194       \u001b[32m0.17893\u001b[0m      0.68151  2.93s\n",
      "     18       0.11866       0.18835      0.63000  2.90s\n",
      "     19       0.12399       0.19883      0.62359  3.08s\n",
      "     20       0.12272       \u001b[32m0.17119\u001b[0m      0.71687  2.95s\n",
      "     21       \u001b[36m0.11519\u001b[0m       0.17308      0.66556  3.12s\n",
      "     22       \u001b[36m0.11414\u001b[0m       0.17249      0.66169  3.04s\n",
      "     23       \u001b[36m0.11182\u001b[0m       0.20884      0.53545  3.07s\n",
      "     24       \u001b[36m0.10339\u001b[0m       \u001b[32m0.16823\u001b[0m      0.61457  3.12s\n",
      "     25       0.11278       0.17254      0.65362  3.05s\n",
      "     26       0.10754       0.19550      0.55007  3.05s\n",
      "     27       0.10342       0.17956      0.57599  3.08s\n",
      "     28       \u001b[36m0.09822\u001b[0m       0.16966      0.57894  3.10s\n",
      "     29       \u001b[36m0.09674\u001b[0m       0.17780      0.54412  3.04s\n",
      "     30       0.10271       0.26404      0.38901  3.06s\n",
      "     31       0.09738       \u001b[32m0.16087\u001b[0m      0.60529  2.97s\n",
      "     32       \u001b[36m0.09158\u001b[0m       0.22190      0.41269  3.13s\n",
      "     33       0.09606       0.17013      0.56464  3.04s\n",
      "     34       \u001b[36m0.08972\u001b[0m       \u001b[32m0.14453\u001b[0m      0.62078  3.04s\n",
      "     35       0.09242       0.18512      0.49924  3.05s\n",
      "     36       0.09210       0.16336      0.56377  3.00s\n",
      "     37       0.09629       0.21522      0.44738  3.02s\n",
      "     38       0.09505       0.16053      0.59212  3.00s\n",
      "     39       0.09368       0.15861      0.59061  2.91s\n",
      "     40       0.09145       0.18962      0.48231  2.96s\n",
      "     41       0.09080       0.16814      0.54003  3.00s\n",
      "     42       0.09050       0.17062      0.53041  3.05s\n",
      "     43       0.09099       \u001b[32m0.13688\u001b[0m      0.66475  2.97s\n",
      "     44       0.09054       \u001b[32m0.13187\u001b[0m      0.68659  2.94s\n",
      "     45       \u001b[36m0.08790\u001b[0m       0.16429      0.53500  2.93s\n",
      "     46       \u001b[36m0.08655\u001b[0m       0.14970      0.57817  2.92s\n",
      "     47       0.08895       0.15174      0.58620  2.89s\n",
      "     48       0.08661       0.15022      0.57653  2.89s\n",
      "     49       0.09033       0.14999      0.60228  3.07s\n",
      "     50       0.08986       0.18085      0.49688  2.93s\n",
      "     51       \u001b[36m0.08274\u001b[0m       0.15854      0.52187  3.14s\n",
      "     52       \u001b[36m0.08209\u001b[0m       0.14623      0.56139  3.08s\n",
      "     53       0.08673       0.14639      0.59244  3.06s\n",
      "     54       0.08743       0.16557      0.52804  3.05s\n",
      "     55       0.08672       0.18826      0.46063  2.93s\n",
      "     56       \u001b[36m0.08191\u001b[0m       0.15695      0.52193  2.92s\n",
      "     57       \u001b[36m0.07694\u001b[0m       0.14407      0.53402  2.90s\n",
      "     58       0.08764       0.18277      0.47952  2.95s\n",
      "     59       0.08451       0.16096      0.52501  2.93s\n",
      "     60       0.07865       0.16172      0.48636  2.93s\n",
      "     61       0.08619       0.24073      0.35803  2.94s\n",
      "     62       0.08418       0.19402      0.43385  2.93s\n",
      "     63       0.08569       0.14207      0.60312  2.94s\n",
      "     64       0.08850       0.15828      0.55915  2.94s\n",
      "     65       0.08537       0.24471      0.34886  2.95s\n",
      "     66       0.08740       0.15073      0.57985  2.92s\n",
      "     67       0.08295       0.15828      0.52405  2.91s\n",
      "     68       0.08158       \u001b[32m0.13141\u001b[0m      0.62086  2.94s\n",
      "     69       0.08476       0.15564      0.54458  2.93s\n",
      "     70       0.08401       0.17003      0.49410  2.93s\n",
      "     71       0.08115       \u001b[32m0.12660\u001b[0m      0.64101  2.95s\n",
      "     72       0.08438       0.12880      0.65514  2.94s\n",
      "     73       0.08465       0.15381      0.55035  2.92s\n",
      "     74       \u001b[36m0.07678\u001b[0m       0.13973      0.54951  2.93s\n",
      "     75       0.08514       0.16888      0.50417  2.96s\n",
      "     76       0.08132       0.14202      0.57257  2.94s\n",
      "     77       \u001b[36m0.07668\u001b[0m       0.15772      0.48619  2.91s\n",
      "     78       0.08352       \u001b[32m0.11378\u001b[0m      0.73403  2.90s\n",
      "     79       0.08052       0.18037      0.44644  2.91s\n",
      "     80       0.07840       0.13706      0.57203  2.93s\n",
      "('Score:', 0.84877468366016062)\n",
      "('Subject:', 2)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.13524\u001b[0m       \u001b[32m0.14012\u001b[0m      0.96523  2.99s\n",
      "      2       \u001b[36m0.11857\u001b[0m       \u001b[32m0.13966\u001b[0m      0.84899  2.93s\n",
      "      3       \u001b[36m0.10994\u001b[0m       \u001b[32m0.13328\u001b[0m      0.82482  2.92s\n",
      "      4       \u001b[36m0.10708\u001b[0m       0.14219      0.75309  2.93s\n",
      "      5       \u001b[36m0.10389\u001b[0m       \u001b[32m0.12099\u001b[0m      0.85871  2.94s\n",
      "      6       \u001b[36m0.10262\u001b[0m       0.12247      0.83793  2.93s\n",
      "      7       0.10500       0.12960      0.81020  2.91s\n",
      "      8       \u001b[36m0.09725\u001b[0m       \u001b[32m0.11546\u001b[0m      0.84227  2.92s\n",
      "      9       0.09844       0.11728      0.83936  2.92s\n",
      "     10       0.10043       \u001b[32m0.11426\u001b[0m      0.87902  2.91s\n",
      "     11       \u001b[36m0.09586\u001b[0m       0.13601      0.70482  2.91s\n",
      "     12       \u001b[36m0.09392\u001b[0m       0.11893      0.78977  2.89s\n",
      "     13       0.09797       0.12645      0.77479  2.89s\n",
      "     14       \u001b[36m0.08983\u001b[0m       0.12489      0.71923  2.91s\n",
      "     15       0.09232       0.12242      0.75410  2.92s\n",
      "     16       \u001b[36m0.08467\u001b[0m       \u001b[32m0.11342\u001b[0m      0.74658  2.91s\n",
      "     17       0.09714       \u001b[32m0.11151\u001b[0m      0.87113  2.88s\n",
      "     18       0.08982       0.12658      0.70955  2.90s\n",
      "     19       0.08999       0.11980      0.75120  2.89s\n",
      "     20       0.09245       0.11290      0.81888  2.90s\n",
      "     21       0.09181       0.11529      0.79632  2.91s\n",
      "     22       0.09039       \u001b[32m0.10864\u001b[0m      0.83198  2.91s\n",
      "     23       0.09045       0.11477      0.78809  2.90s\n",
      "     24       0.08756       0.10959      0.79895  2.90s\n",
      "     25       0.08524       \u001b[32m0.10762\u001b[0m      0.79201  2.90s\n",
      "     26       0.08657       \u001b[32m0.10557\u001b[0m      0.82003  2.93s\n",
      "     27       0.09363       0.12913      0.72506  2.89s\n",
      "     28       0.08800       0.12055      0.72999  2.89s\n",
      "     29       \u001b[36m0.08387\u001b[0m       0.12437      0.67439  2.91s\n",
      "     30       0.08544       0.11254      0.75926  2.90s\n",
      "     31       \u001b[36m0.08069\u001b[0m       0.13845      0.58286  2.92s\n",
      "     32       0.08653       0.10629      0.81412  2.91s\n",
      "     33       0.08609       0.11956      0.72007  2.93s\n",
      "     34       0.08312       0.10816      0.76849  2.90s\n",
      "     35       0.08724       0.12274      0.71078  2.94s\n",
      "     36       0.08682       0.11675      0.74358  2.93s\n",
      "     37       0.08522       0.11524      0.73952  2.89s\n",
      "     38       0.09100       0.11182      0.81386  2.89s\n",
      "     39       0.08598       0.12534      0.68600  2.93s\n",
      "     40       0.08655       0.11115      0.77874  2.94s\n",
      "     41       0.08814       0.11236      0.78448  2.93s\n",
      "     42       0.08439       0.11096      0.76054  2.90s\n",
      "     43       0.08811       0.11217      0.78552  2.90s\n",
      "     44       0.08427       0.11374      0.74094  2.89s\n",
      "     45       0.08528       0.11605      0.73489  2.89s\n",
      "     46       0.08177       0.12411      0.65885  2.91s\n",
      "     47       0.08646       0.11983      0.72151  2.91s\n",
      "     48       0.08804       0.12746      0.69069  2.92s\n",
      "     49       0.08630       0.11349      0.76043  2.91s\n",
      "     50       0.08451       0.11395      0.74164  2.92s\n",
      "('Score:', 0.54139486766861111)\n",
      "('Subject:', 3)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.14790\u001b[0m       \u001b[32m0.17876\u001b[0m      0.82735  2.88s\n",
      "      2       \u001b[36m0.13823\u001b[0m       \u001b[32m0.16209\u001b[0m      0.85279  2.84s\n",
      "      3       \u001b[36m0.13035\u001b[0m       0.16243      0.80251  2.87s\n",
      "      4       \u001b[36m0.12905\u001b[0m       \u001b[32m0.12664\u001b[0m      1.01901  2.86s\n",
      "      5       \u001b[36m0.12055\u001b[0m       0.15479      0.77880  2.87s\n",
      "      6       0.12561       0.16360      0.76782  2.90s\n",
      "      7       \u001b[36m0.11488\u001b[0m       0.17006      0.67551  2.89s\n",
      "      8       0.11853       0.15198      0.77995  2.87s\n",
      "      9       \u001b[36m0.10554\u001b[0m       0.16376      0.64446  2.91s\n",
      "     10       0.12109       0.15497      0.78138  2.91s\n",
      "     11       0.10962       0.15197      0.72131  2.91s\n",
      "     12       0.10734       0.15849      0.67730  2.89s\n",
      "     13       0.11049       0.16663      0.66309  2.87s\n",
      "     14       0.11410       0.14896      0.76600  2.87s\n",
      "     15       0.11788       \u001b[32m0.12278\u001b[0m      0.96006  2.89s\n",
      "     16       \u001b[36m0.10517\u001b[0m       0.16931      0.62118  2.88s\n",
      "     17       0.11096       0.16190      0.68539  2.89s\n",
      "     18       0.10589       0.14395      0.73559  2.90s\n",
      "     19       0.10670       0.15537      0.68679  2.90s\n",
      "     20       \u001b[36m0.10227\u001b[0m       0.13701      0.74644  2.91s\n",
      "     21       0.10632       0.15225      0.69835  2.91s\n",
      "     22       0.10495       0.13811      0.75992  2.92s\n",
      "     23       \u001b[36m0.10068\u001b[0m       0.14840      0.67841  2.94s\n",
      "     24       0.10714       0.15669      0.68380  2.89s\n",
      "     25       0.10672       0.12941      0.82465  2.90s\n",
      "     26       0.10612       \u001b[32m0.11878\u001b[0m      0.89337  2.92s\n",
      "     27       0.10095       0.14468      0.69773  2.91s\n",
      "     28       0.11098       0.13136      0.84486  2.91s\n",
      "     29       0.10370       0.14763      0.70241  2.88s\n",
      "     30       \u001b[36m0.09959\u001b[0m       0.15212      0.65469  2.88s\n",
      "     31       0.10767       0.14686      0.73317  2.92s\n",
      "     32       0.10255       0.14563      0.70423  2.93s\n",
      "     33       0.10534       0.17412      0.60500  2.91s\n",
      "     34       \u001b[36m0.09412\u001b[0m       0.14908      0.63139  2.89s\n",
      "     35       0.09811       0.15366      0.63846  2.92s\n",
      "     36       0.10673       0.16024      0.66602  2.90s\n",
      "     37       0.09871       0.13401      0.73657  2.91s\n",
      "     38       0.10224       0.15713      0.65068  2.92s\n",
      "     39       0.09844       0.15648      0.62907  2.91s\n",
      "     40       0.09767       0.16081      0.60738  2.88s\n",
      "     41       0.09973       0.15319      0.65103  2.91s\n",
      "     42       0.10579       0.14797      0.71491  2.91s\n",
      "     43       0.10287       0.14784      0.69583  2.88s\n",
      "     44       0.09580       0.15187      0.63083  2.93s\n",
      "     45       0.09950       0.16059      0.61961  2.91s\n",
      "     46       0.09973       0.18003      0.55398  2.88s\n",
      "     47       0.10036       0.15927      0.63015  2.88s\n",
      "     48       0.10319       0.15145      0.68131  2.86s\n",
      "     49       0.10382       0.16695      0.62186  2.90s\n",
      "     50       \u001b[36m0.09228\u001b[0m       0.16261      0.56749  2.91s\n",
      "('Score:', 0.7863328116849243)\n",
      "('Subject:', 4)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.13301\u001b[0m       \u001b[32m0.11729\u001b[0m      1.13406  2.93s\n",
      "      2       \u001b[36m0.10328\u001b[0m       \u001b[32m0.10109\u001b[0m      1.02175  2.91s\n",
      "      3       0.10875       0.10319      1.05385  2.90s\n",
      "      4       \u001b[36m0.10177\u001b[0m       \u001b[32m0.08881\u001b[0m      1.14590  2.89s\n",
      "      5       \u001b[36m0.09742\u001b[0m       0.10077      0.96673  2.90s\n",
      "      6       0.10121       0.09575      1.05709  2.93s\n",
      "      7       \u001b[36m0.09215\u001b[0m       \u001b[32m0.08601\u001b[0m      1.07143  2.93s\n",
      "      8       0.09705       0.09605      1.01044  2.92s\n",
      "      9       0.09445       0.09516      0.99250  2.91s\n",
      "     10       0.09263       0.09444      0.98092  2.91s\n",
      "     11       0.09473       0.09634      0.98328  2.91s\n",
      "     12       0.09417       0.09809      0.96005  2.89s\n",
      "     13       \u001b[36m0.08873\u001b[0m       \u001b[32m0.08268\u001b[0m      1.07318  2.89s\n",
      "     14       \u001b[36m0.08800\u001b[0m       0.08279      1.06283  2.94s\n",
      "     15       \u001b[36m0.08710\u001b[0m       0.08357      1.04228  2.91s\n",
      "     16       0.08985       0.08950      1.00390  2.91s\n",
      "     17       0.09183       0.08718      1.05336  2.90s\n",
      "     18       \u001b[36m0.08597\u001b[0m       0.09209      0.93362  2.89s\n",
      "     19       0.09167       0.08285      1.10646  2.89s\n",
      "     20       0.09185       0.10229      0.89798  2.92s\n",
      "     21       0.08921       0.09444      0.94463  2.93s\n",
      "     22       0.08913       0.09299      0.95850  2.90s\n",
      "     23       0.08765       0.09652      0.90818  2.88s\n",
      "     24       0.09196       0.08765      1.04907  2.89s\n",
      "     25       0.08641       0.09420      0.91730  2.86s\n",
      "     26       0.08673       0.09089      0.95417  2.92s\n",
      "     27       0.08949       0.08880      1.00775  2.92s\n",
      "     28       0.08815       0.08710      1.01203  2.90s\n",
      "     29       0.08929       0.09268      0.96338  2.89s\n",
      "     30       0.08720       0.10480      0.83212  2.92s\n",
      "     31       \u001b[36m0.08509\u001b[0m       0.10090      0.84334  2.92s\n",
      "     32       0.09162       0.09920      0.92358  2.88s\n",
      "     33       0.08765       0.08625      1.01621  2.91s\n",
      "     34       0.08866       0.09305      0.95282  2.91s\n",
      "     35       0.08875       0.08877      0.99985  2.91s\n",
      "     36       0.09021       \u001b[32m0.08027\u001b[0m      1.12376  2.93s\n",
      "     37       0.09049       0.08514      1.06277  2.91s\n",
      "     38       0.08587       0.09033      0.95072  2.93s\n",
      "     39       0.09035       0.09471      0.95401  2.92s\n",
      "     40       0.08924       0.09395      0.94991  2.91s\n",
      "     41       0.09068       0.08801      1.03040  2.91s\n",
      "     42       0.08533       0.08622      0.98963  2.92s\n",
      "     43       \u001b[36m0.08476\u001b[0m       0.08915      0.95074  2.90s\n",
      "     44       0.09161       0.08674      1.05609  2.90s\n",
      "     45       0.09117       0.09068      1.00542  2.92s\n",
      "     46       \u001b[36m0.08449\u001b[0m       0.08809      0.95915  2.91s\n",
      "     47       0.08561       0.09739      0.87898  2.89s\n",
      "     48       0.08461       0.09179      0.92173  2.91s\n",
      "     49       0.08727       0.09677      0.90177  2.90s\n",
      "     50       0.09041       0.08517      1.06156  2.91s\n",
      "('Score:', 0.94799166350890485)\n",
      "('Subject:', 5)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.12082\u001b[0m       \u001b[32m0.16245\u001b[0m      0.74372  2.90s\n",
      "      2       \u001b[36m0.11346\u001b[0m       \u001b[32m0.12141\u001b[0m      0.93450  2.86s\n",
      "      3       \u001b[36m0.10767\u001b[0m       0.14136      0.76168  2.90s\n",
      "      4       0.11165       \u001b[32m0.11537\u001b[0m      0.96773  2.89s\n",
      "      5       0.10812       0.12465      0.86733  2.89s\n",
      "      6       \u001b[36m0.10713\u001b[0m       0.11686      0.91674  2.88s\n",
      "      7       \u001b[36m0.09918\u001b[0m       \u001b[32m0.11075\u001b[0m      0.89555  2.89s\n",
      "      8       0.09920       \u001b[32m0.10863\u001b[0m      0.91319  2.89s\n",
      "      9       0.10543       0.11424      0.92292  2.89s\n",
      "     10       0.10196       \u001b[32m0.10828\u001b[0m      0.94162  2.88s\n",
      "     11       0.10570       0.12101      0.87345  2.89s\n",
      "     12       0.10022       \u001b[32m0.10817\u001b[0m      0.92655  2.88s\n",
      "     13       \u001b[36m0.09739\u001b[0m       0.11726      0.83054  2.89s\n",
      "     14       0.10551       \u001b[32m0.10752\u001b[0m      0.98133  2.90s\n",
      "     15       \u001b[36m0.09573\u001b[0m       0.11070      0.86480  2.87s\n",
      "     16       0.10264       \u001b[32m0.10086\u001b[0m      1.01766  2.86s\n",
      "     17       0.09920       0.11683      0.84906  2.91s\n",
      "     18       0.09846       0.11643      0.84565  2.89s\n",
      "     19       0.09912       0.10125      0.97895  2.89s\n",
      "     20       0.10349       0.11819      0.87557  2.89s\n",
      "     21       0.10128       0.10964      0.92375  2.88s\n",
      "     22       0.09716       0.11061      0.87839  2.88s\n",
      "     23       0.09772       0.12182      0.80220  2.90s\n",
      "     24       0.09741       0.11972      0.81362  2.92s\n",
      "     25       0.09623       0.11366      0.84670  2.86s\n",
      "     26       \u001b[36m0.09550\u001b[0m       0.11254      0.84858  2.91s\n",
      "     27       0.09702       0.11890      0.81603  2.90s\n",
      "     28       \u001b[36m0.09173\u001b[0m       0.11797      0.77755  2.90s\n",
      "     29       0.09563       0.11860      0.80629  2.94s\n",
      "     30       0.09323       0.14232      0.65509  2.90s\n",
      "     31       0.09555       0.10656      0.89665  2.87s\n",
      "     32       0.10192       0.13702      0.74381  2.89s\n",
      "     33       0.09917       0.11786      0.84143  2.90s\n",
      "     34       0.10350       0.11433      0.90531  2.85s\n",
      "     35       0.09826       0.11794      0.83308  2.88s\n",
      "     36       0.10496       0.12460      0.84235  2.89s\n",
      "     37       0.09865       0.11019      0.89532  2.89s\n",
      "     38       0.09986       0.11162      0.89465  2.91s\n",
      "     39       0.09388       0.11073      0.84783  2.86s\n",
      "     40       0.10034       0.10295      0.97458  2.91s\n",
      "     41       0.09564       0.10609      0.90150  2.91s\n",
      "     42       0.09876       0.10215      0.96680  2.91s\n",
      "     43       0.09545       0.10720      0.89035  2.90s\n",
      "     44       0.10171       0.10937      0.92989  2.90s\n",
      "     45       0.09194       0.11070      0.83050  2.88s\n",
      "     46       0.09313       0.11892      0.78318  2.88s\n",
      "     47       0.09317       0.11332      0.82217  2.90s\n",
      "     48       0.10078       0.11244      0.89637  2.86s\n",
      "     49       0.09797       0.12429      0.78825  2.87s\n",
      "     50       0.09938       0.10743      0.92511  2.88s\n",
      "('Score:', 0.80321690301703619)\n",
      "('Subject:', 6)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.11679\u001b[0m       \u001b[32m0.11076\u001b[0m      1.05444  2.83s\n",
      "      2       \u001b[36m0.11206\u001b[0m       0.12788      0.87627  2.86s\n",
      "      3       \u001b[36m0.10362\u001b[0m       0.11913      0.86981  2.88s\n",
      "      4       0.10775       0.11081      0.97239  2.89s\n",
      "      5       0.10977       0.11298      0.97160  2.88s\n",
      "      6       \u001b[36m0.09807\u001b[0m       0.12023      0.81566  2.91s\n",
      "      7       \u001b[36m0.09656\u001b[0m       0.12111      0.79729  2.88s\n",
      "      8       0.10135       0.11997      0.84482  2.88s\n",
      "      9       \u001b[36m0.09544\u001b[0m       \u001b[32m0.10888\u001b[0m      0.87653  2.87s\n",
      "     10       0.09756       0.11615      0.83997  2.90s\n",
      "     11       0.09680       \u001b[32m0.10223\u001b[0m      0.94690  2.86s\n",
      "     12       0.09776       0.11349      0.86135  2.89s\n",
      "     13       \u001b[36m0.09376\u001b[0m       0.11802      0.79446  2.91s\n",
      "     14       0.09437       0.11641      0.81067  2.88s\n",
      "     15       0.09606       0.12306      0.78056  2.87s\n",
      "     16       \u001b[36m0.09256\u001b[0m       0.11524      0.80319  2.89s\n",
      "     17       \u001b[36m0.09150\u001b[0m       0.11138      0.82146  2.87s\n",
      "     18       \u001b[36m0.08775\u001b[0m       0.12152      0.72210  2.88s\n",
      "     19       0.09603       0.11348      0.84624  2.87s\n",
      "     20       0.09119       0.11053      0.82505  2.87s\n",
      "     21       \u001b[36m0.08203\u001b[0m       0.11118      0.73779  2.88s\n",
      "     22       0.09376       0.12311      0.76161  2.85s\n",
      "     23       0.08682       0.10631      0.81674  2.87s\n",
      "     24       0.09347       0.12507      0.74738  2.88s\n",
      "     25       0.09291       0.11842      0.78454  2.89s\n",
      "     26       0.08444       0.11461      0.73680  2.88s\n",
      "     27       0.08689       0.10765      0.80715  2.90s\n",
      "     28       0.08872       0.11790      0.75248  2.87s\n",
      "     29       0.08984       0.11606      0.77408  2.87s\n",
      "     30       0.08418       0.11545      0.72911  2.89s\n",
      "     31       0.09560       0.13054      0.73233  2.88s\n",
      "     32       \u001b[36m0.08194\u001b[0m       0.11485      0.71343  2.86s\n",
      "     33       0.08677       0.10862      0.79889  2.87s\n",
      "     34       0.09241       0.11504      0.80328  2.86s\n",
      "     35       0.08503       0.11851      0.71755  2.88s\n",
      "     36       0.08597       0.11270      0.76280  2.87s\n",
      "     37       \u001b[36m0.08151\u001b[0m       0.11092      0.73485  2.87s\n",
      "     38       0.08593       0.11679      0.73574  2.84s\n",
      "     39       0.08618       0.11688      0.73730  2.86s\n",
      "     40       \u001b[36m0.07821\u001b[0m       0.11171      0.70006  2.87s\n",
      "     41       0.08734       0.12638      0.69111  2.89s\n",
      "     42       0.07948       0.11465      0.69328  2.91s\n",
      "     43       0.08732       0.11893      0.73419  2.87s\n",
      "     44       0.08190       0.11240      0.72867  2.90s\n",
      "     45       \u001b[36m0.07671\u001b[0m       0.10660      0.71962  2.87s\n",
      "     46       0.08674       0.11837      0.73279  2.86s\n",
      "     47       0.08028       0.10584      0.75848  2.89s\n",
      "     48       0.08205       0.11763      0.69753  2.89s\n",
      "     49       0.07804       0.11413      0.68376  2.90s\n",
      "     50       0.08192       0.11699      0.70018  2.86s\n",
      "('Score:', 0.91561815932235646)\n",
      "('Subject:', 7)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.08741\u001b[0m       \u001b[32m0.10492\u001b[0m      0.83313  2.85s\n",
      "      2       \u001b[36m0.08599\u001b[0m       \u001b[32m0.09823\u001b[0m      0.87539  2.84s\n",
      "      3       \u001b[36m0.07886\u001b[0m       \u001b[32m0.09383\u001b[0m      0.84048  2.82s\n",
      "      4       0.08213       0.09844      0.83436  2.84s\n",
      "      5       0.07965       0.09530      0.83583  2.86s\n",
      "      6       \u001b[36m0.07554\u001b[0m       \u001b[32m0.08657\u001b[0m      0.87254  2.84s\n",
      "      7       0.07793       0.09770      0.79760  2.80s\n",
      "      8       0.08240       0.10184      0.80904  2.85s\n",
      "      9       \u001b[36m0.07468\u001b[0m       0.09208      0.81100  2.84s\n",
      "     10       0.07984       0.09146      0.87289  2.85s\n",
      "     11       0.08073       0.10243      0.78813  2.84s\n",
      "     12       0.07943       0.09993      0.79486  2.84s\n",
      "     13       0.07601       0.09354      0.81263  2.87s\n",
      "     14       0.07506       0.08881      0.84518  2.84s\n",
      "     15       0.08088       0.08933      0.90538  2.84s\n",
      "     16       \u001b[36m0.07246\u001b[0m       0.08821      0.82146  2.88s\n",
      "     17       0.07700       \u001b[32m0.08636\u001b[0m      0.89165  2.89s\n",
      "     18       0.07494       0.09854      0.76053  2.89s\n",
      "     19       0.07384       0.09498      0.77742  2.86s\n",
      "     20       0.07496       \u001b[32m0.08471\u001b[0m      0.88495  2.88s\n",
      "     21       \u001b[36m0.07235\u001b[0m       0.08971      0.80652  2.85s\n",
      "     22       0.07755       0.08651      0.89641  2.86s\n",
      "     23       0.07643       0.09093      0.84053  2.90s\n",
      "     24       0.07512       \u001b[32m0.08379\u001b[0m      0.89653  2.84s\n",
      "     25       0.07940       0.09924      0.80009  2.90s\n",
      "     26       \u001b[36m0.06994\u001b[0m       0.09769      0.71589  2.84s\n",
      "     27       0.07260       0.09224      0.78710  2.87s\n",
      "     28       0.07411       0.09206      0.80498  2.88s\n",
      "     29       0.07367       0.08935      0.82446  2.83s\n",
      "     30       0.07678       0.09052      0.84821  2.86s\n",
      "     31       0.07752       0.10643      0.72843  2.85s\n",
      "     32       0.07519       0.08668      0.86747  2.88s\n",
      "     33       \u001b[36m0.06901\u001b[0m       0.09014      0.76560  2.86s\n",
      "     34       0.07127       \u001b[32m0.07739\u001b[0m      0.92092  2.85s\n",
      "     35       0.07258       \u001b[32m0.07721\u001b[0m      0.94002  2.88s\n",
      "     36       0.07443       0.09414      0.79057  2.86s\n",
      "     37       0.07247       0.08536      0.84899  2.88s\n",
      "     38       0.07452       0.09465      0.78731  2.85s\n",
      "     39       0.07059       0.08999      0.78441  2.87s\n",
      "     40       0.07179       0.08255      0.86966  2.84s\n",
      "     41       0.07145       0.08435      0.84707  2.87s\n",
      "     42       0.07281       0.08955      0.81306  2.85s\n",
      "     43       0.07207       0.09226      0.78115  2.87s\n",
      "     44       0.07391       0.09134      0.80922  2.86s\n",
      "     45       0.07487       0.09961      0.75156  2.88s\n",
      "     46       0.07075       0.08718      0.81159  2.86s\n",
      "     47       0.07141       0.08828      0.80889  2.89s\n",
      "     48       0.07078       0.08795      0.80482  2.88s\n",
      "     49       0.07414       0.09534      0.77768  2.88s\n",
      "     50       0.07325       0.09430      0.77675  2.87s\n",
      "('Score:', 0.8746972457400064)\n",
      "('Subject:', 8)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.16290\u001b[0m       \u001b[32m0.13219\u001b[0m      1.23234  2.92s\n",
      "      2       \u001b[36m0.14429\u001b[0m       \u001b[32m0.11856\u001b[0m      1.21707  2.91s\n",
      "      3       \u001b[36m0.12721\u001b[0m       0.12105      1.05089  2.89s\n",
      "      4       0.13152       \u001b[32m0.11815\u001b[0m      1.11318  2.95s\n",
      "      5       0.13166       \u001b[32m0.11507\u001b[0m      1.14414  2.91s\n",
      "      6       \u001b[36m0.12339\u001b[0m       \u001b[32m0.11295\u001b[0m      1.09250  2.88s\n",
      "      7       0.13121       \u001b[32m0.11080\u001b[0m      1.18413  2.91s\n",
      "      8       \u001b[36m0.12018\u001b[0m       \u001b[32m0.10962\u001b[0m      1.09632  2.93s\n",
      "      9       \u001b[36m0.11783\u001b[0m       \u001b[32m0.10479\u001b[0m      1.12442  2.91s\n",
      "     10       0.12102       0.11677      1.03638  2.92s\n",
      "     11       0.12492       0.10929      1.14296  2.90s\n",
      "     12       \u001b[36m0.11574\u001b[0m       0.10974      1.05466  2.92s\n",
      "     13       0.12368       0.10859      1.13898  2.89s\n",
      "     14       \u001b[36m0.11430\u001b[0m       0.10699      1.06832  2.93s\n",
      "     15       0.12607       \u001b[32m0.10333\u001b[0m      1.22008  2.90s\n",
      "     16       0.12399       \u001b[32m0.09731\u001b[0m      1.27420  2.91s\n",
      "     17       0.12249       0.10600      1.15557  2.90s\n",
      "     18       0.11690       0.09900      1.18082  2.86s\n",
      "     19       0.11927       0.11454      1.04131  2.94s\n",
      "     20       \u001b[36m0.11160\u001b[0m       0.10547      1.05805  2.93s\n",
      "     21       0.11872       0.10935      1.08576  2.89s\n",
      "     22       \u001b[36m0.11084\u001b[0m       \u001b[32m0.09556\u001b[0m      1.15985  2.92s\n",
      "     23       0.11731       0.10633      1.10324  2.89s\n",
      "     24       0.11158       0.10832      1.03010  2.90s\n",
      "     25       0.11315       0.10392      1.08874  2.88s\n",
      "     26       0.11497       0.11829      0.97194  2.90s\n",
      "     27       0.11306       0.10274      1.10040  2.89s\n",
      "     28       0.11773       0.10891      1.08099  2.90s\n",
      "     29       0.11995       0.09882      1.21379  2.92s\n",
      "     30       0.11368       0.09845      1.15469  2.89s\n",
      "     31       \u001b[36m0.10967\u001b[0m       0.10610      1.03359  2.91s\n",
      "     32       0.11541       0.11430      1.00967  2.93s\n",
      "     33       0.11379       0.10930      1.04110  2.93s\n",
      "     34       0.11587       0.10429      1.11109  2.90s\n",
      "     35       0.11834       0.10785      1.09726  2.88s\n",
      "     36       0.11233       0.10585      1.06115  2.90s\n",
      "     37       \u001b[36m0.10581\u001b[0m       0.10497      1.00800  2.90s\n",
      "     38       0.10984       0.10247      1.07198  2.93s\n",
      "     39       0.11607       0.09884      1.17436  2.89s\n",
      "     40       0.11567       0.10274      1.12583  2.87s\n",
      "     41       0.11622       0.10731      1.08301  2.89s\n",
      "     42       0.11278       0.10841      1.04032  2.89s\n",
      "     43       0.12428       0.10334      1.20263  2.94s\n",
      "     44       0.11182       0.10127      1.10420  2.90s\n",
      "     45       0.11325       0.10702      1.05829  2.95s\n",
      "     46       0.10842       0.09963      1.08820  2.93s\n",
      "     47       0.11718       0.10234      1.14505  2.94s\n",
      "     48       0.11317       0.09771      1.15818  2.91s\n",
      "     49       0.11217       0.10427      1.07576  2.92s\n",
      "     50       0.11352       0.09851      1.15241  2.92s\n",
      "('Score:', 0.87703409174582136)\n",
      "('Subject:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.12362\u001b[0m       \u001b[32m0.13336\u001b[0m      0.92692  2.89s\n",
      "      2       \u001b[36m0.10340\u001b[0m       \u001b[32m0.12817\u001b[0m      0.80674  2.91s\n",
      "      3       \u001b[36m0.09920\u001b[0m       0.13566      0.73125  2.89s\n",
      "      4       0.09967       \u001b[32m0.12777\u001b[0m      0.78004  2.91s\n",
      "      5       \u001b[36m0.09318\u001b[0m       \u001b[32m0.11141\u001b[0m      0.83641  2.94s\n",
      "      6       0.09722       0.13840      0.70242  2.87s\n",
      "      7       \u001b[36m0.09267\u001b[0m       0.12396      0.74757  2.91s\n",
      "      8       \u001b[36m0.08827\u001b[0m       0.11721      0.75307  2.91s\n",
      "      9       \u001b[36m0.08801\u001b[0m       0.14565      0.60425  2.91s\n",
      "     10       \u001b[36m0.08652\u001b[0m       \u001b[32m0.10789\u001b[0m      0.80195  2.93s\n",
      "     11       0.09176       0.12093      0.75874  2.91s\n",
      "     12       0.08997       0.11294      0.79669  2.88s\n",
      "     13       \u001b[36m0.08646\u001b[0m       \u001b[32m0.09772\u001b[0m      0.88481  2.89s\n",
      "     14       \u001b[36m0.08533\u001b[0m       0.09956      0.85708  2.91s\n",
      "     15       \u001b[36m0.08095\u001b[0m       0.10382      0.77972  2.88s\n",
      "     16       0.08179       0.12611      0.64856  2.90s\n",
      "     17       0.08294       0.11834      0.70089  2.90s\n",
      "     18       0.08993       0.10944      0.82176  2.93s\n",
      "     19       \u001b[36m0.08033\u001b[0m       0.10296      0.78020  2.92s\n",
      "     20       0.08658       0.10907      0.79379  2.89s\n",
      "     21       0.08102       0.11758      0.68906  2.86s\n",
      "     22       0.08576       0.12546      0.68357  2.90s\n",
      "     23       \u001b[36m0.07427\u001b[0m       \u001b[32m0.08887\u001b[0m      0.83573  2.87s\n",
      "     24       0.08444       0.13643      0.61888  2.89s\n",
      "     25       0.08177       0.14893      0.54905  2.89s\n",
      "     26       0.08033       0.10838      0.74119  2.90s\n",
      "     27       0.08396       0.11757      0.71413  2.91s\n",
      "     28       0.08200       0.11952      0.68607  2.90s\n",
      "     29       0.08429       0.13095      0.64366  2.87s\n",
      "     30       0.08278       0.10616      0.77980  2.88s\n",
      "     31       0.08281       0.14237      0.58161  2.87s\n",
      "     32       0.08051       0.14841      0.54246  2.88s\n",
      "     33       0.08388       0.12595      0.66596  2.90s\n",
      "     34       0.08060       0.10657      0.75632  2.86s\n",
      "     35       0.07928       0.12316      0.64370  2.90s\n",
      "     36       0.07722       0.13461      0.57367  2.91s\n",
      "     37       0.08605       0.12915      0.66628  2.89s\n",
      "     38       0.08135       0.11086      0.73380  2.90s\n",
      "     39       0.07703       0.10687      0.72082  2.88s\n",
      "     40       0.07926       0.09831      0.80624  2.88s\n",
      "     41       0.07558       0.13316      0.56759  2.84s\n",
      "     42       0.07978       0.10858      0.73476  2.87s\n",
      "     43       0.08166       0.10014      0.81540  2.87s\n",
      "     44       0.08032       0.09507      0.84481  2.87s\n",
      "     45       0.07679       0.10060      0.76334  2.86s\n",
      "     46       0.08220       0.12780      0.64321  2.89s\n",
      "     47       0.07971       0.10641      0.74914  2.88s\n",
      "     48       0.07558       0.15249      0.49565  2.86s\n",
      "     49       0.08709       0.11072      0.78654  2.86s\n",
      "     50       0.08013       0.11682      0.68590  2.89s\n",
      "('Score:', 0.92269621750912867)\n",
      "('Subject:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.10310\u001b[0m       \u001b[32m0.07897\u001b[0m      1.30556  2.86s\n",
      "      2       \u001b[36m0.09054\u001b[0m       \u001b[32m0.07877\u001b[0m      1.14945  2.89s\n",
      "      3       0.09500       0.08630      1.10079  2.89s\n",
      "      4       0.09341       0.08476      1.10208  2.86s\n",
      "      5       \u001b[36m0.08741\u001b[0m       \u001b[32m0.07778\u001b[0m      1.12391  2.87s\n",
      "      6       \u001b[36m0.08643\u001b[0m       \u001b[32m0.07716\u001b[0m      1.12021  2.91s\n",
      "      7       \u001b[36m0.08468\u001b[0m       \u001b[32m0.07516\u001b[0m      1.12671  2.86s\n",
      "      8       \u001b[36m0.08291\u001b[0m       0.07618      1.08831  2.90s\n",
      "      9       \u001b[36m0.08218\u001b[0m       0.08371      0.98168  2.88s\n",
      "     10       0.08549       0.07855      1.08839  2.88s\n",
      "     11       0.08310       0.07972      1.04245  2.88s\n",
      "     12       0.08492       0.07521      1.12918  2.88s\n",
      "     13       \u001b[36m0.07857\u001b[0m       0.08685      0.90465  2.89s\n",
      "     14       \u001b[36m0.07784\u001b[0m       0.08466      0.91943  2.87s\n",
      "     15       0.07992       0.07923      1.00866  2.92s\n",
      "     16       0.08553       0.08213      1.04141  2.88s\n",
      "     17       0.08326       0.07979      1.04356  2.97s\n",
      "     18       0.08559       0.07750      1.10441  2.88s\n",
      "     19       0.08320       \u001b[32m0.07351\u001b[0m      1.13174  2.91s\n",
      "     20       0.08129       0.07828      1.03839  2.90s\n",
      "     21       0.08174       0.07998      1.02199  2.89s\n",
      "     22       0.08011       0.08670      0.92392  2.90s\n",
      "     23       0.08174       0.08616      0.94875  2.86s\n",
      "     24       0.08398       0.08574      0.97947  2.88s\n",
      "     25       0.08138       0.08671      0.93855  2.90s\n",
      "     26       0.08016       0.07781      1.03024  2.88s\n",
      "     27       0.08472       0.07495      1.13038  2.90s\n",
      "     28       0.08234       0.08471      0.97201  2.90s\n",
      "     29       0.07901       0.08512      0.92817  2.90s\n",
      "     30       0.08954       0.09015      0.99327  2.90s\n",
      "     31       0.08297       0.08916      0.93061  2.90s\n",
      "     32       0.07886       0.08523      0.92530  2.90s\n",
      "     33       0.08573       0.08659      0.99003  2.89s\n",
      "     34       0.08387       0.07837      1.07014  2.91s\n",
      "     35       0.08451       0.07598      1.11223  2.88s\n",
      "     36       0.08188       0.08114      1.00913  2.91s\n",
      "     37       0.08303       0.08100      1.02514  2.86s\n",
      "     38       0.08090       0.07596      1.06500  2.92s\n",
      "     39       0.08762       0.07650      1.14538  2.91s\n",
      "     40       0.08146       0.08414      0.96818  2.89s\n",
      "     41       0.08070       0.08005      1.00810  2.90s\n",
      "     42       0.08116       0.08653      0.93798  2.89s\n",
      "     43       0.08088       0.08198      0.98658  2.89s\n",
      "     44       0.07787       0.07735      1.00678  2.85s\n",
      "     45       \u001b[36m0.07718\u001b[0m       \u001b[32m0.07052\u001b[0m      1.09448  2.90s\n",
      "     46       0.08236       0.08123      1.01386  2.90s\n",
      "     47       0.07752       0.08072      0.96038  2.90s\n",
      "     48       \u001b[36m0.07689\u001b[0m       0.08231      0.93418  2.87s\n",
      "     49       0.07912       0.07267      1.08875  2.89s\n",
      "     50       0.08068       0.07762      1.03950  2.91s\n",
      "('Score:', 0.92315023163467902)\n",
      "('Subject:', 11)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.12199\u001b[0m       \u001b[32m0.11871\u001b[0m      1.02763  2.92s\n",
      "      2       \u001b[36m0.09750\u001b[0m       \u001b[32m0.10901\u001b[0m      0.89441  2.88s\n",
      "      3       \u001b[36m0.09015\u001b[0m       0.10922      0.82540  2.90s\n",
      "      4       \u001b[36m0.08650\u001b[0m       0.10981      0.78774  2.88s\n",
      "      5       0.09107       \u001b[32m0.10623\u001b[0m      0.85725  2.90s\n",
      "      6       0.08989       0.11704      0.76805  2.89s\n",
      "      7       \u001b[36m0.08444\u001b[0m       \u001b[32m0.10333\u001b[0m      0.81724  2.95s\n",
      "      8       0.08594       \u001b[32m0.09999\u001b[0m      0.85942  2.90s\n",
      "      9       0.08668       0.10153      0.85372  2.91s\n",
      "     10       \u001b[36m0.08396\u001b[0m       0.10394      0.80775  2.92s\n",
      "     11       0.08665       0.10822      0.80074  2.93s\n",
      "     12       0.08704       \u001b[32m0.09722\u001b[0m      0.89528  2.91s\n",
      "     13       0.08591       0.10678      0.80454  2.89s\n",
      "     14       0.08686       0.10385      0.83644  2.90s\n",
      "     15       \u001b[36m0.08374\u001b[0m       0.09944      0.84211  2.90s\n",
      "     16       \u001b[36m0.08120\u001b[0m       0.09991      0.81280  2.90s\n",
      "     17       0.08674       0.10093      0.85945  2.90s\n",
      "     18       0.08254       \u001b[32m0.09287\u001b[0m      0.88881  2.91s\n",
      "     19       0.08392       0.10179      0.82442  2.89s\n",
      "     20       0.08267       0.10061      0.82173  2.91s\n",
      "     21       0.08341       0.09395      0.88788  2.91s\n",
      "     22       0.08343       0.09753      0.85546  2.92s\n",
      "     23       \u001b[36m0.08015\u001b[0m       \u001b[32m0.08082\u001b[0m      0.99168  2.90s\n",
      "     24       0.08153       0.09991      0.81598  2.89s\n",
      "     25       0.08067       0.10524      0.76651  2.91s\n",
      "     26       0.08225       0.09479      0.86768  2.94s\n",
      "     27       0.08042       0.09704      0.82878  2.93s\n",
      "     28       0.08267       0.10198      0.81069  2.91s\n",
      "     29       \u001b[36m0.07942\u001b[0m       0.09085      0.87414  2.93s\n",
      "     30       0.08225       0.10504      0.78305  2.89s\n",
      "     31       \u001b[36m0.07814\u001b[0m       0.09597      0.81420  2.87s\n",
      "     32       \u001b[36m0.07801\u001b[0m       0.09041      0.86288  2.89s\n",
      "     33       0.08139       0.09579      0.84963  2.91s\n",
      "     34       0.08469       0.09363      0.90455  2.92s\n",
      "     35       0.08253       0.10037      0.82223  2.92s\n",
      "     36       \u001b[36m0.07777\u001b[0m       0.11266      0.69032  2.90s\n",
      "     37       \u001b[36m0.07762\u001b[0m       0.08694      0.89284  2.91s\n",
      "     38       0.08016       0.09495      0.84424  2.90s\n",
      "     39       \u001b[36m0.07740\u001b[0m       0.09884      0.78314  2.90s\n",
      "     40       0.08286       0.10136      0.81743  2.92s\n",
      "     41       0.07835       0.08526      0.91891  2.93s\n",
      "     42       0.07859       0.09775      0.80398  2.91s\n",
      "     43       \u001b[36m0.07690\u001b[0m       0.09501      0.80934  2.91s\n",
      "     44       \u001b[36m0.07586\u001b[0m       0.08666      0.87542  2.89s\n",
      "     45       0.08004       0.09091      0.88044  2.91s\n",
      "     46       0.07962       0.08985      0.88617  2.91s\n",
      "     47       0.07654       0.09665      0.79190  2.89s\n",
      "     48       0.07925       0.08210      0.96533  2.90s\n",
      "     49       \u001b[36m0.07357\u001b[0m       0.10228      0.71930  2.89s\n",
      "     50       0.07625       0.09078      0.83989  2.89s\n",
      "('Score:', 0.85310928006058107)\n",
      "('Subject:', 12)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "# Neural Network with 1581362 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name     size\n",
      "---  -------  ------\n",
      "  0  layer1   32x256\n",
      "  1  layer2   32x256\n",
      "  2  layer3   4x256\n",
      "  3  layer4   8x256\n",
      "  4  layer5   8x64\n",
      "  5  layer6   8x64\n",
      "  6  layer7   1024\n",
      "  7  layer8   1024\n",
      "  8  layer9   1024\n",
      "  9  layer10  1024\n",
      " 10  output   6\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  -----\n",
      "      1       \u001b[36m0.11144\u001b[0m       \u001b[32m0.11782\u001b[0m      0.94591  2.94s\n",
      "      2       \u001b[36m0.09656\u001b[0m       0.11869      0.81355  3.05s\n",
      "      3       \u001b[36m0.09273\u001b[0m       \u001b[32m0.10171\u001b[0m      0.91169  3.16s\n",
      "      4       0.09779       \u001b[32m0.09210\u001b[0m      1.06175  3.21s\n",
      "      5       0.09305       0.09698      0.95942  3.15s\n",
      "      6       \u001b[36m0.09231\u001b[0m       0.10724      0.86076  3.16s\n",
      "      7       \u001b[36m0.08850\u001b[0m       0.10054      0.88029  3.05s\n",
      "      8       0.09392       0.09505      0.98811  2.99s\n",
      "      9       0.09230       0.09732      0.94841  2.97s\n",
      "     10       0.09142       \u001b[32m0.08056\u001b[0m      1.13473  2.90s\n",
      "     11       \u001b[36m0.08713\u001b[0m       0.09557      0.91164  2.92s\n",
      "     12       \u001b[36m0.08452\u001b[0m       0.09579      0.88234  3.07s\n",
      "     13       0.09393       0.09758      0.96260  3.22s\n",
      "     14       0.09153       0.09691      0.94451  3.07s\n",
      "     15       0.08932       0.09761      0.91504  3.05s\n",
      "     16       0.08987       0.10319      0.87095  3.01s\n",
      "     17       \u001b[36m0.08335\u001b[0m       0.09267      0.89942  2.97s\n",
      "     18       0.08607       0.08342      1.03183  3.09s\n",
      "     19       0.08660       0.09558      0.90605  3.10s\n",
      "     20       0.08629       0.09709      0.88881  2.91s\n",
      "     21       0.08963       0.08893      1.00787  2.97s\n",
      "     22       0.08852       0.09379      0.94382  3.08s\n",
      "     23       0.08703       0.09172      0.94885  2.95s\n",
      "     24       \u001b[36m0.08030\u001b[0m       0.08926      0.89964  3.00s\n",
      "     25       0.08227       0.08476      0.97068  3.05s\n",
      "     26       0.08390       0.10101      0.83065  2.93s\n",
      "     27       0.08921       0.09050      0.98566  3.06s\n",
      "     28       0.08202       0.09359      0.87629  2.93s\n",
      "     29       \u001b[36m0.07966\u001b[0m       0.09653      0.82525  2.90s\n",
      "     30       0.08359       0.09920      0.84265  2.88s\n",
      "     31       0.08965       0.09606      0.93331  2.90s\n",
      "     32       0.08170       0.08599      0.95008  2.90s\n",
      "     33       0.08175       0.08316      0.98304  2.92s\n",
      "     34       0.08444       0.08794      0.96026  2.91s\n",
      "     35       0.08020       0.08668      0.92525  2.88s\n",
      "     36       0.08244       0.09058      0.91007  2.91s\n",
      "     37       0.08239       0.08417      0.97895  2.91s\n",
      "     38       0.08835       0.09736      0.90744  2.91s\n",
      "     39       0.07969       0.10312      0.77276  2.91s\n",
      "     40       0.08036       0.08707      0.92291  2.90s\n",
      "     41       0.08188       0.09797      0.83578  2.95s\n",
      "     42       0.08403       0.09200      0.91331  2.93s\n",
      "     43       0.08647       0.09370      0.92282  2.90s\n",
      "     44       0.08225       0.09166      0.89737  2.94s\n",
      "     45       \u001b[36m0.07455\u001b[0m       0.08292      0.89909  2.94s\n",
      "     46       0.08283       0.08974      0.92298  2.91s\n",
      "     47       0.08871       0.09636      0.92059  2.88s\n",
      "     48       0.08093       0.08992      0.90003  2.92s\n",
      "     49       0.08331       0.09787      0.85130  2.91s\n",
      "     50       0.08266       0.09203      0.89818  2.92s\n",
      "('Score:', 0.86148738379814072)\n",
      "('Subject:', 1, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 1, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 2, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 2, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 3, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 3, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 4, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 4, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 5, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 5, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 6, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 6, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 7, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 7, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 8, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 8, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 9, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 9, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 10, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 10, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 11, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 11, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 12, ', series:', 9)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n",
      "('Subject:', 12, ', series:', 10)\n",
      "Loaded parameters to layer 'layer3' (shape 4x32x1).\n",
      "Loaded parameters to layer 'layer3' (shape 4).\n",
      "Loaded parameters to layer 'layer4' (shape 8x4x5).\n",
      "Loaded parameters to layer 'layer4' (shape 8).\n",
      "Loaded parameters to layer 'layer7' (shape 512x1024).\n",
      "Loaded parameters to layer 'layer7' (shape 1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024x1024).\n",
      "Loaded parameters to layer 'layer9' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x6).\n",
      "Loaded parameters to layer 'output' (shape 6).\n"
     ]
    }
   ],
   "source": [
    "# Do the training.\n",
    "\n",
    "train_indices = np.zeros([TRAIN_SIZE], dtype=int) - 1\n",
    "\n",
    "def score(net, samples=256):\n",
    "    \"\"\"Compute the area under the curve, ROC score\n",
    "    We take `samples` random samples and compute the ROC AUC\n",
    "    score on those samples. \n",
    "    \"\"\"\n",
    "    source = net.batch_iterator_test.source\n",
    "    test_indices = np.arange(len(source.events))\n",
    "    np.random.seed(199)\n",
    "    np.random.shuffle(test_indices)\n",
    "    predicted = net.predict_proba(test_indices[:samples])\n",
    "    actual = source.events[test_indices[:samples]]\n",
    "    return roc_auc_score(actual.reshape(-1), predicted.reshape(-1))\n",
    "    \n",
    "\n",
    "def train(factory, subj, max_epochs=20, valid_series=[3,6], params=None): #ES valid_series=[1,2]\n",
    "    tseries = sorted(set(TRAIN_SERIES) - set(valid_series))\n",
    "    train_source = TrainSource(subj, tseries)\n",
    "    test_source = TestSource(subj, valid_series, train_source)\n",
    "    net = factory(train_source, test_source, max_epochs=max_epochs)\n",
    "    if params is not None:\n",
    "        net.load_params_from(params)\n",
    "    net.fit(train_indices, train_indices)\n",
    "    print(\"Score:\", score(net))\n",
    "    return (net, train_source)\n",
    " \n",
    "\n",
    "def train_all(factory, max_epochs=30, init_epochs=30, valid_series=[1,2]):\n",
    "    info = {}\n",
    "    params = None\n",
    "    for subj in SUBJECTS:\n",
    "        print(\"Subject:\", subj)\n",
    "        epochs = max_epochs + init_epochs\n",
    "        net, train_source = train(factory, subj, epochs, valid_series, params)\n",
    "        params = net.get_all_params_values()\n",
    "        info[subj] = (params, train_source)\n",
    "        init_epochs = 0\n",
    "    return (factory, info)   \n",
    "  \n",
    " \n",
    "def make_submission(train_info, name):\n",
    "    factory, info = train_info\n",
    "    with open(name, 'w') as file:\n",
    "        file.write(\"id,HandStart,FirstDigitTouch,BothStartLoadPhase,LiftOff,Replace,BothReleased\\n\")\n",
    "        for subj in SUBJECTS:\n",
    "            weights, train_source = info[subj]\n",
    "            for series in [9,10]:\n",
    "                print(\"Subject:\", subj, \", series:\", series)\n",
    "                submit_source = SubmitSource(subj, series, train_source)  \n",
    "                indices = np.arange(len(submit_source.data))\n",
    "                net = factory(train_source=None, test_source=submit_source)\n",
    "                net.load_weights_from(weights)\n",
    "                probs = net.predict_proba(indices)\n",
    "                for i, p in enumerate(probs):\n",
    "                    id = \"subj{0}_series{1}_{2},\".format(subj, series, i)\n",
    "                    file.write(id + \",\".join(str(x) for x in p) + '\\n')\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    train_info = train_all(create_net, max_epochs=50) # Training for longer would likley be better ES:max_epochs=25\n",
    "    make_submission(train_info, \"naive_grasp.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submission = pd.read_csv('naive_grasp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3144171"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
